[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "loss/likelihood.html",
    "href": "loss/likelihood.html",
    "title": "Likelihood and Model Quality",
    "section": "",
    "text": "Likelihood measures how well a model with fixed parameters explains the observed data.",
    "crumbs": [
      "Loss Functions",
      "Likelihood and Model Quality"
    ]
  },
  {
    "objectID": "loss/likelihood.html#what-problem-does-likelihood-solve",
    "href": "loss/likelihood.html#what-problem-does-likelihood-solve",
    "title": "Likelihood and Model Quality",
    "section": "",
    "text": "Likelihood measures how well a model with fixed parameters explains the observed data.",
    "crumbs": [
      "Loss Functions",
      "Likelihood and Model Quality"
    ]
  },
  {
    "objectID": "loss/likelihood.html#why-is-it-a-product-over-data-points",
    "href": "loss/likelihood.html#why-is-it-a-product-over-data-points",
    "title": "Likelihood and Model Quality",
    "section": "Why is it a product over data points?",
    "text": "Why is it a product over data points?\nBecause we assume data points are independent. This means the joint probability factors into a product.",
    "crumbs": [
      "Loss Functions",
      "Likelihood and Model Quality"
    ]
  },
  {
    "objectID": "loss/likelihood.html#why-does-this-relate-to-loss-functions",
    "href": "loss/likelihood.html#why-does-this-relate-to-loss-functions",
    "title": "Likelihood and Model Quality",
    "section": "Why does this relate to loss functions?",
    "text": "Why does this relate to loss functions?\nTaking the negative log-likelihood converts likelihood into a loss that can be minimized during training.",
    "crumbs": [
      "Loss Functions",
      "Likelihood and Model Quality"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Deep Learning Notes",
    "section": "",
    "text": "These are my personal notes on deep learning, starting from loss functions and probabilistic modeling.\nThe goal is understanding assumptions and reasoning, not coverage.\n\ntest",
    "crumbs": [
      "Deep Learning Notes"
    ]
  }
]